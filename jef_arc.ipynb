{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqnjvoAT6oa5",
        "outputId": "3372e40e-f10b-460f-b4d9-2b2f5ae4bd3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error fetching source https://www.nato.int/cps/en/natohq/news_190311.htm: 403 Client Error: Forbidden for url: https://www.nato.int/cps/en/natohq/news_190311.htm\n",
            "Error fetching source https://www.arctic-council.org/en/: 403 Client Error: Forbidden for url: https://www.arctic-council.org/en/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-27c134ce1171>:38: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
            "  for link in soup.find_all(\"a\", href=True, text=re.compile(keyword, re.IGNORECASE)):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error fetching source https://www.mil.dk/en/: HTTPSConnectionPool(host='www.mil.dk', port=443): Max retries exceeded with url: /en/ (Caused by SSLError(SSLError(1, '[SSL: TLSV1_UNRECOGNIZED_NAME] tlsv1 unrecognized name (_ssl.c:1006)')))\n",
            "Error fetching article from /en/exercises-and-operations: Invalid URL '/en/exercises-and-operations': No scheme supplied. Perhaps you meant https:///en/exercises-and-operations?\n",
            "Error fetching article from /en/exercises-and-operations: Invalid URL '/en/exercises-and-operations': No scheme supplied. Perhaps you meant https:///en/exercises-and-operations?\n",
            "Error fetching source https://www.mil.ca/: HTTPSConnectionPool(host='www.mil.ca', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f566c6ba050>: Failed to resolve 'www.mil.ca' ([Errno -2] Name or service not known)\"))\n",
            "Error fetching source https://www.althingi.is/: 403 Client Error: Forbidden for url: https://www.althingi.is/\n",
            "Error fetching source https://www.defensie.nl/en/: 404 Client Error: Not Found for url: https://www.defensie.nl/en/\n"
          ]
        }
      ],
      "source": [
        "# prompt: Scrape the web for statements and speeches regarding Joint Expeditionary Force activities in the Arctic...include quotations from secondary sources as well\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "def scrape_arctic_statements(keywords):\n",
        "  \"\"\"Scrapes web pages for statements and speeches related to the Joint Expeditionary Force (JEF)\n",
        "  and Arctic activities, including quotations from secondary sources.\n",
        "\n",
        "  Args:\n",
        "    keywords: A list of keywords to search for (e.g., ['Joint Expeditionary Force', 'Arctic', 'NATO']).\n",
        "\n",
        "  Returns:\n",
        "    A list of dictionaries, where each dictionary represents a found statement/speech and\n",
        "    contains information like the title, source, URL, and extracted text.\n",
        "  \"\"\"\n",
        "  statements = []\n",
        "  # Add more relevant news sources and websites here.\n",
        "  sources = [\n",
        "      \"https://www.nato.int/cps/en/natohq/news_190311.htm\", # NATO Website\n",
        "      \"https://www.arctic-council.org/en/\", # Arctic Council\n",
        "      \"https://www.gov.uk/government/publications\", # UK government publications\n",
        "      \"https://www.mil.dk/en/\", # Danish military\n",
        "      \"https://www.forsvaret.no/en/\", # Norwegian military\n",
        "      \"https://www.mil.ca/\", # Canadian military\n",
        "      \"https://www.althingi.is/\", # Icelandic Parliament\n",
        "      \"https://www.gov.ie/\", # Irish Government\n",
        "      \"https://www.defensie.nl/en/\", # Netherlands defense\n",
        "  ]\n",
        "\n",
        "  for source in sources:\n",
        "    try:\n",
        "      response = requests.get(source)\n",
        "      response.raise_for_status()  # Raise an exception for bad status codes\n",
        "      soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "      for keyword in keywords:\n",
        "        for link in soup.find_all(\"a\", href=True, text=re.compile(keyword, re.IGNORECASE)):\n",
        "          article_url = link[\"href\"]\n",
        "          try:\n",
        "            article_response = requests.get(article_url)\n",
        "            article_response.raise_for_status()\n",
        "            article_soup = BeautifulSoup(article_response.content, \"html.parser\")\n",
        "            title = article_soup.title.string if article_soup.title else \"No Title\"\n",
        "            text = article_soup.get_text()\n",
        "\n",
        "            statements.append({\n",
        "                \"title\": title,\n",
        "                \"source\": source,\n",
        "                \"url\": article_url,\n",
        "                \"text\": text\n",
        "            })\n",
        "\n",
        "          except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error fetching article from {article_url}: {e}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "      print(f\"Error fetching source {source}: {e}\")\n",
        "\n",
        "  return statements\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  keywords = [\"Joint Expeditionary Force\", \"Arctic\", \"NATO\", \"defence\", \"security\", \"operations\"]\n",
        "\n",
        "  found_statements = scrape_arctic_statements(keywords)\n",
        "\n",
        "  for statement in found_statements:\n",
        "    print(\"-\" * 20)\n",
        "    print(f\"Title: {statement['title']}\")\n",
        "    print(f\"Source: {statement['source']}\")\n",
        "    print(f\"URL: {statement['url']}\")\n",
        "    # You can process the 'text' further to extract quotes and specific information\n",
        "    print(f\"Text Snippet: {statement['text'][:200]}...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import re\n",
        "\n",
        "# Custom headers to mimic a browser\n",
        "headers = {\n",
        "    'User-Agent': ('Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n",
        "                   'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
        "                   'Chrome/112.0.0.0 Safari/537.36'),\n",
        "    'Referer': 'https://www.google.com/'\n",
        "}\n",
        "\n",
        "# List of alliance websites with likely news/statement pages.\n",
        "# You might need to update these URLs to point to pages that list statements.\n",
        "urls = [\n",
        "    \"https://bucharest9.org/en/news\",         # Bucharest Nine news/statements page\n",
        "    \"https://www.jef.int/en/news\",             # Joint Expeditionary Force (JEF) news\n",
        "    \"https://www.visegradgroup.eu/en/news\",    # Visegrad Group news/statements\n",
        "    \"https://nordefco.org/news\",               # NORDEFCO news/statements (if available)\n",
        "    # Additional similar alliances can be added here:\n",
        "    \"https://three-seas.eu/en/news\",           # Three Seas Initiative news\n",
        "    \"https://lublintriangle.eu/en/news\",       # Lublin Triangle (if available)\n",
        "    \"https://ukpolukraine.org/en/news\"          # UK-Poland-Ukraine Trilateral Initiative (if available)\n",
        "]\n",
        "\n",
        "def fetch_page(url):\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        return response.content\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Request failed for {url}: {e}\")\n",
        "        return None\n",
        "\n",
        "def extract_recent_statements(html):\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    content = \"\"\n",
        "\n",
        "    # Look for article or post blocks; this selector might need customization per site.\n",
        "    for article in soup.find_all(['article', 'div'],\n",
        "                                 class_=lambda c: c and re.search(r'(news|post|statement)', c, re.IGNORECASE)):\n",
        "        # Optionally, check for a publication date within the article, and skip if not recent.\n",
        "        # For example, if dates are stored in a <time> tag with attribute datetime.\n",
        "        date_tag = article.find('time')\n",
        "        if date_tag and date_tag.get('datetime'):\n",
        "            # Here, you can parse the date and filter if older than a threshold.\n",
        "            pass\n",
        "\n",
        "        text = article.get_text(separator='\\n', strip=True)\n",
        "        if text:\n",
        "            content += text + \"\\n\\n\" + \"=\"*80 + \"\\n\\n\"\n",
        "\n",
        "    # Fallback: if no structured articles were found, grab main content from a common container.\n",
        "    if not content:\n",
        "        main_content = soup.find('main')\n",
        "        if main_content:\n",
        "            content = main_content.get_text(separator='\\n', strip=True)\n",
        "    return content\n",
        "\n",
        "final_content = \"\"\n",
        "\n",
        "for url in urls:\n",
        "    print(f\"Processing {url}\")\n",
        "    html = fetch_page(url)\n",
        "    if html:\n",
        "        extracted = extract_recent_statements(html)\n",
        "        if extracted:\n",
        "            final_content += f\"--- Content from {url} ---\\n\\n\" + extracted + \"\\n\"\n",
        "    time.sleep(1)  # Delay to avoid overwhelming servers\n",
        "\n",
        "output_filename = \"small_scale_alliance_statements.txt\"\n",
        "with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "    f.write(final_content)\n",
        "\n",
        "print(f\"Scraping complete. Data saved to '{output_filename}'\")\n"
      ],
      "metadata": {
        "id": "XlHd_K927d3E",
        "outputId": "a7c9f056-d4e1-44e2-cff8-d061d8934619",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing https://bucharest9.org/en/news\n",
            "Request failed for https://bucharest9.org/en/news: HTTPSConnectionPool(host='bucharest9.org', port=443): Max retries exceeded with url: /en/news (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f566c7ed190>: Failed to resolve 'bucharest9.org' ([Errno -2] Name or service not known)\"))\n",
            "Processing https://www.jef.int/en/news\n",
            "Request failed for https://www.jef.int/en/news: HTTPSConnectionPool(host='www.jef.int', port=443): Max retries exceeded with url: /en/news (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f566c6bdbd0>: Failed to resolve 'www.jef.int' ([Errno -2] Name or service not known)\"))\n",
            "Processing https://www.visegradgroup.eu/en/news\n",
            "Request failed for https://www.visegradgroup.eu/en/news: 404 Client Error: Not Found for url: https://www.visegradgroup.eu/en/news\n",
            "Processing https://nordefco.org/news\n",
            "Request failed for https://nordefco.org/news: HTTPSConnectionPool(host='nordefco.org', port=443): Max retries exceeded with url: /news (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f566c5460d0>: Failed to resolve 'nordefco.org' ([Errno -5] No address associated with hostname)\"))\n",
            "Processing https://three-seas.eu/en/news\n",
            "Request failed for https://three-seas.eu/en/news: HTTPSConnectionPool(host='three-seas.eu', port=443): Max retries exceeded with url: /en/news (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f566c55c510>, 'Connection to three-seas.eu timed out. (connect timeout=10)'))\n",
            "Processing https://lublintriangle.eu/en/news\n",
            "Request failed for https://lublintriangle.eu/en/news: HTTPSConnectionPool(host='lublintriangle.eu', port=443): Max retries exceeded with url: /en/news (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f566c55e510>: Failed to resolve 'lublintriangle.eu' ([Errno -2] Name or service not known)\"))\n",
            "Processing https://ukpolukraine.org/en/news\n",
            "Request failed for https://ukpolukraine.org/en/news: HTTPSConnectionPool(host='ukpolukraine.org', port=443): Max retries exceeded with url: /en/news (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7f566c55fb50>: Failed to resolve 'ukpolukraine.org' ([Errno -2] Name or service not known)\"))\n",
            "Scraping complete. Data saved to 'small_scale_alliance_statements.txt'\n"
          ]
        }
      ]
    }
  ]
}